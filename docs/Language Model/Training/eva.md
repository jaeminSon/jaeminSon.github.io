---
title: (논문 요약) One Initialization to Rule them All; Fine-tuning via Explained Variance Adaptation
parent: Training
---

**(논문 요약) One Initialization to Rule them All: Fine-tuning via Explained Variance Adaptation** [(Paper)](https://arxiv.org/pdf/2410.07170)


## 핵심 내용
- In LoRA, initialize the new weights in a data-driven manner
   - *by computing singular value decomposition on minibatches of activation vectors.*

<img src="/data/papers/eva/concept.png" width="800" />



## 실험 결과
<img src="/data/papers/eva/result.png" width="800" />
