---
title: (논문 요약) Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?
parent: Hallucination
---

**(논문 요약) Does Fine-Tuning LLMs on New Knowledge Encourage Hallucinations?** [(Paper)](https://arxiv.org/pdf/2405.05904)


## 핵심 내용
- ***large language models mostly acquire factual knowledge through pre-training, whereas finetuning teaches them to use it more efficiently***

## 실험 결과
<img src="/data/papers/finetuning-hallucination/result0.png" width="500" />
<img src="/data/papers/finetuning-hallucination/result1.png" width="800" />
<img src="/data/papers/finetuning-hallucination/result2.png" width="800" />
<img src="/data/papers/finetuning-hallucination/result3.png" width="800" />

